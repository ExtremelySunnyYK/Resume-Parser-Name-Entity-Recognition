{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Contact www.linkedin.com/in/ivanthinks (LinkedIn) ivanzhou.org (Personal) medium.com/@ivanthinks (Blog) Top Skills Data Engineering Cloud Computing Deep Learning Certifications Natural Language Processing in TensorFlow Device-based Models with TensorFlow Lite Deep Learning Specialization Wharton School of Business - Financial Accounting Structuring Machine Learning Projects Honors-Awards Dean's Honor List 2nd Place in RBC Innovative Design Competition 2nd Place in ASA DataFest Competition by Google Undergraduate Student Research Award Centennial Thesis Awards Publications Aesthetic Features for Personalized Photo Recommendation Uber Driver Schedule Optimization Nonlinear Hybrid Planning with Deep Net Learned Transition Models and Mixed-Integer Linear Programming Ivan Zhou Machine Learning Engineer at Landing AI San Francisco Summary Machine Learning Engineer by training and photographer by heart. I love computer vision in many ways. Experience Landing AI Machine Learning Engineer November 2018\\xa0-\\xa0Present\\xa0(2 years 2 months) San Francisco Bay Area - Implement the state-of-the art deep learning algorithms to solve defect detection problems in manufacturing at >99% precision and recall. I led the team to win a client-host competition and outperformed teams from Baidu, Alibaba, and Petuum by a significant margin in two weeks. - Deploy end-to-end inference pipeline with multiple machine learning models to Nvidia Jetson edge devices. Optimize algorithms to run at milliseconds latency to provide real-time inference results at the manufacturing lines. - Develop automatic provisioning, CI/CD, OTA deployment, and monitoring solutions so that the machines operate in factories at a 24/7 schedule with minimum downtime. - Developed the first labeling book for data collection, the first camera solution for data collection in extreme environments, the first edge-device solution, and the first end-to-end usability test for the Machine Learning platform. Be able to deliver exceptionally high-quality results under high pressure and great ambiguity. Shopify 10 months Machine Learning Engineer, Personalization and Discovery Algorithm June 2018\\xa0-\\xa0October 2018\\xa0(5 months) Toronto, Canada Area - Image Search and Personalization in production \\xa0 Page 1 of 5 - End-to-End data science support for a fast-growing photo marketplace (Shopify's Burst), from setting up data infrastructure to algorithm implementation and product analytics - Machine Learning research: publication in ACM RecSys 2018 Machine Learning Engineer, Marketing Technology January 2018\\xa0-\\xa0May 2018\\xa0(5 months) Toronto, Canada Area - Develop recommender systems in production with Spark and Hadoop System. - Apply the state-of-the-art machine learning algorithms to build the IQ system in Shopify. University of Toronto Research Assistant on Deep Learning August 2016\\xa0-\\xa0July 2018\\xa0(2 years) Toronto, Canada Area - Published a paper in IJCAI2017 on non-linear planning with Deep Net as a co-author. - Apply Neural Network and Mixed-integer Linear Programming in large scale system planning. - Apply Deep Autoencoder in unsupervised anomaly detection in the domain of Cybersecurity. - Supervised by Professor Sanner in the Data Driven Decision Making Lab.  - Received Undergraduate Summer Research Award from NSERC. Mozilla Capstone Student, NLP September 2017\\xa0-\\xa0April 2018\\xa0(8 months) Toronto, Canada Area - Developed an end-to-end user feedback analytics engine for Mozilla Firefox team to process thousands of users feedbacks in real time, with functions including translation, sentiment analysis, categorization, and visualization.  - The tool has been deployed in Mozilla's internal server and used by global Mozilla employees.  500px Deep Learning Research Intern - Recommender System August 2017\\xa0-\\xa0April 2018\\xa0(9 months) Toronto, Canada Area \\xa0 Page 2 of 5 - Develop machine learning systems to recommend 500px users with photos that they will most likely to enjoy with.  - Implement a variety of state-of-the-art recommender system algorithms, including K-NN, SVM Matrix Factorization, LRec, and Linear FLow. Improve the performance through techniques like temporal decay.  - Develop a novel algorithm to quantify photos’ visual features and embed them into the recommender system. Bell Business Intelligence Consultant May 2016\\xa0-\\xa0July 2016\\xa0(3 months) - Analyzed business processes in Customer Operations and developed a solution with $14 million net revenue increase over 5 years. - Identified inconsistency in business process and led a process change that would bring a net benefit of $400K in one year - Worked with large data volumes efficiently using SAS and SQL to create customer segmentation algorithm, prediction models for customer behavior, and operations process optimization. - Provided services to over 200 Bell customers on phone and develop strategies to reduce the Average Calling Time by 58% and improve Customer Feedback Rate by 94% Dyson Sales Analyst, Business Intelligence May 2015\\xa0-\\xa0April 2016\\xa0(1 year) Toronto Canada - Develop sales forecast and optimize strategies for the national Business Development Team based on market analytics - Designed the Evaluation Metrics for distributors based on Salesforce and SAP data, optimized national distribution network based on sales strategies, and droved up sales in distributors by 119%. - Researched on potential vertical markets for Dyson Airblade hand dryers, and generated over 3,000 high quality leads through data mining. - In collaboration with UK and US teams, apply expertise in Operation Research and consulting skills, redesign the process of CRM and Sales Cycle Development.   Digital Trinity Labs Co-Founder, Chief Data Scientist \\xa0 Page 3 of 5 April 2015\\xa0-\\xa0March 2016\\xa0(1 year) - Build up connection between young professional in colleges and local start- ups community. Facilitate the exchange of product ideas, industrial insight, and network intelligence.  - Inspire fellows to get hand-on experience in Data Science, UI/UX Design, and Web/App Development through professional project development for clients. - Actively initiate and engage in long term collaboration with local startups across industries, including but not limited to: Crowdfunding, P2P Lending, Social Ventures, and Game Engine Development..  - Deliver professional work in Front-End, Back-End, Apps Development, Database Management, Data Visualization, and Operation Management. Westcan Yacht Club Inc Business Analyst June 2014\\xa0-\\xa0August 2014\\xa0(3 months) - Set up CRM system, recording customers’ preference, history of maintenance, and potential interest in a new purchase, to facilitate data-based decision making and execution of sales team. - Assist Canadian Sail & Power Squadron and International Yacht Training Worldwide (IYT) to provide customers standard IYT yacht courses with certifications. EXCITE2014 Co-Chair - Entrepreneurship Conference October 2013\\xa0-\\xa0March 2014\\xa0(6 months) Toronto, Canada Area - Led a small conference committee to bring the largest entrepreneurship conference at the University of Toronto to life, benefiting 500 students and young professionals and generated over $16,000 in revenue. - Featured the VP Public Affairs and Communications of Coca-Cola, CTO of Microsoft Canada, and Institute Director of Toronto Rehabilitation Institute. - Organized an internship-guaranteed business case competition in collaboration with Toronto Rehabilitation Institute of University Health Network, attracting 35 student teams to compete - Executed an aggressive marketing plan and successfully sold all 500 tickets within three weeks - Outreached professors in Engineering, Computer Science, and Rotman Commerce to promote our conference among targeted students.  - Oversee the logistic and operation of the conference. \\xa0 Page 4 of 5 Model United Nations Club in High School Attached to the Shanghai Normal University Founder, President September 2011\\xa0-\\xa0September 2012\\xa0(1 year 1 month) - Started up my own Model United Nations (MUN) Club in my secondary school.  - Recruit club members, trained them of the knowledge and skills of negotiation and communication in MUN meetings.  - Approach local MUN communities for networking and educational seminars. - Lead my team to participate in three provincial MUN meetings and receive honour as the best delegate team twice.  - Organize one provincial MUN meetings by our own. Education Stanford University Graduate Certificate,\\xa0Artificial Intelligence\\xa0·\\xa0(2019\\xa0-\\xa02021) University of Toronto Engineer’s Degree,\\xa0Industrial Engineering, Business/Commerce, General\\xa0·\\xa0(2013\\xa0-\\xa0June 2018) Udacity Certificate,\\xa0Self-Driving Car Engineering\\xa0·\\xa0(2016\\xa0-\\xa02017) Johns Hopkins Bloomberg School of Public Health Certificate,\\xa0Data Science Specialist\\xa0·\\xa0(2014\\xa0-\\xa02015) \\xa0 Page 5 of 5 \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../resume_parser/')\n",
    "import resume_parser\n",
    "# from resume_parser import resume_parser\n",
    "\n",
    "jd_path = \"../data/JD/Software Engineer Intern in ML Engineering Platform (System) - 2021 Summer - ByteDance.pdf\"\n",
    "resume_path = \"../data/resume/ivan_machine_learning_engineer.pdf\"\n",
    "job_description = resume_parser.get_text(jd_path)\n",
    "resume = resume_parser.get_text(resume_path)\n",
    "\n",
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chang_Ker_Fui.docx',\n",
       " 'Chang_Ker_Fui_Resume.pdf',\n",
       " 'ivan_machine_learning_engineer.pdf',\n",
       " 'Jaryl Lim Resume.docx',\n",
       " 'machine_learning_engineer_airbnb.pdf',\n",
       " 'resumes.zip',\n",
       " 'Ruolin_zhang_psych.pdf',\n",
       " 'sample_input.pdf',\n",
       " 'sample_output.txt',\n",
       " 'testdata.json',\n",
       " 'traindata.json',\n",
       " 'train_data.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../data/resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/yk09/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/yk09/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# A list of text\n",
    "text = [resume, job_description]\n",
    "predefined_stop_words = [\"the\",\"a\",\"is\",\"you\",\"your\",\"will\"]\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "resume = re.sub(r'[0-9]', '',resume).replace(u'\\xa0', u' ')\n",
    "job_description = re.sub(r'[0-9]', '',job_description).replace(u'\\xa0', u' ')\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stop_words = list(set(stopwords.words('english'))) + predefined_stop_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline method with cosine similarity and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/yk09/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/yk09/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "../data/resume/ivan_machine_learning_engineer.pdf\n",
      "\n",
      "Similarity Scores Lemma and stopwords:\n",
      "[[1.       0.625759]\n",
      " [0.625759 1.      ]]\n",
      "\n",
      "Similarity Scores Lemma without stop words:\n",
      "[[1.         0.69737129]\n",
      " [0.69737129 1.        ]]\n",
      "\n",
      "Similarity Scores Lemma without stop words:\n",
      "[[1.         0.26869837]\n",
      " [0.26869837 1.        ]]\n",
      "\n",
      "Similarity Scores without lemma and stop words:\n",
      "[[1.         0.66345316]\n",
      " [0.66345316 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# A list of text\n",
    "text = [resume, job_description]\n",
    "predefined_stop_words = [\"the\",\"a\",\"is\",\"you\",\"your\",\"will\"]\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "resume = re.sub(r'[0-9]', '',resume).replace(u'\\xa0', u' ')\n",
    "job_description = re.sub(r'[0-9]', '',job_description).replace(u'\\xa0', u' ')\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stop_words = list(set(stopwords.words('english'))) + predefined_stop_words\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Lemma and Token\n",
    "print(resume_path)\n",
    "cv = CountVectorizer(tokenizer=LemmaTokenizer(),stop_words=stop_words)\n",
    "# generates word counts for the words in resume and jd \n",
    "count_matrix = cv.fit_transform(text)\n",
    "#Print the similarity scores\n",
    "print(\"\\nSimilarity Scores Lemma and stopwords:\")\n",
    "print(cosine_similarity(count_matrix))\n",
    "\n",
    "# Lemma without stop words\n",
    "cv = CountVectorizer(tokenizer=LemmaTokenizer())\n",
    "count_matrix = cv.fit_transform(text)\n",
    "#Print the similarity scores\n",
    "print(\"\\nSimilarity Scores Lemma without stop words:\")\n",
    "print(cosine_similarity(count_matrix))\n",
    "\n",
    "# Stop words without lemma\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "count_matrix = cv.fit_transform(text)\n",
    "#Print the similarity scores\n",
    "print(\"\\nSimilarity Scores Lemma without stop words:\")\n",
    "print(cosine_similarity(count_matrix))\n",
    "\n",
    "# without lemma and stop words\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text)\n",
    "#Print the similarity scores\n",
    "print(\"\\nSimilarity Scores without lemma and stop words:\")\n",
    "print(cosine_similarity(count_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = count_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                        columns=cv.get_feature_names(), \n",
    "                        index=['resume', 'job_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abilities',\n",
       " 'able',\n",
       " 'about',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accounting',\n",
       " 'achieve',\n",
       " 'acm',\n",
       " 'across',\n",
       " 'actively',\n",
       " 'aesthetic',\n",
       " 'affairs',\n",
       " 'after',\n",
       " 'aggressive',\n",
       " 'ai',\n",
       " 'airblade',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'alibaba',\n",
       " 'all',\n",
       " 'ambiguity',\n",
       " 'among',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytical',\n",
       " 'analytics',\n",
       " 'analyzed',\n",
       " 'and',\n",
       " 'anomaly',\n",
       " 'app',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'apply',\n",
       " 'approach',\n",
       " 'apps',\n",
       " 'april',\n",
       " 'architecture',\n",
       " 'are',\n",
       " 'area',\n",
       " 'art',\n",
       " 'artificial',\n",
       " 'as',\n",
       " 'asa',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'at',\n",
       " 'attached',\n",
       " 'attracting',\n",
       " 'august',\n",
       " 'author',\n",
       " 'autoencoder',\n",
       " 'automatic',\n",
       " 'available',\n",
       " 'average',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'back',\n",
       " 'background',\n",
       " 'baidu',\n",
       " 'based',\n",
       " 'basis',\n",
       " 'bay',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'behavior',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'benefit',\n",
       " 'benefiting',\n",
       " 'best',\n",
       " 'between',\n",
       " 'blog',\n",
       " 'bloomberg',\n",
       " 'book',\n",
       " 'bring',\n",
       " 'build',\n",
       " 'burst',\n",
       " 'business',\n",
       " 'but',\n",
       " 'by',\n",
       " 'bytedance',\n",
       " 'calling',\n",
       " 'camera',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'capstone',\n",
       " 'car',\n",
       " 'case',\n",
       " 'categorization',\n",
       " 'cd',\n",
       " 'celebrating',\n",
       " 'centennial',\n",
       " 'certificate',\n",
       " 'certifications',\n",
       " 'chair',\n",
       " 'change',\n",
       " 'chief',\n",
       " 'ci',\n",
       " 'client',\n",
       " 'clients',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'cluster',\n",
       " 'co',\n",
       " 'coca',\n",
       " 'cola',\n",
       " 'collaboration',\n",
       " 'collection',\n",
       " 'colleges',\n",
       " 'com',\n",
       " 'commerce',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compete',\n",
       " 'competition',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'conference',\n",
       " 'connection',\n",
       " 'connects',\n",
       " 'considered',\n",
       " 'consultant',\n",
       " 'consulting',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'contributing',\n",
       " 'courses',\n",
       " 'create',\n",
       " 'creating',\n",
       " 'creativity',\n",
       " 'crm',\n",
       " 'crowdfunding',\n",
       " 'cto',\n",
       " 'cultures',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'cybersecurity',\n",
       " 'cycle',\n",
       " 'data',\n",
       " 'database',\n",
       " 'datafest',\n",
       " 'deadline',\n",
       " 'dean',\n",
       " 'dec',\n",
       " 'decay',\n",
       " 'decision',\n",
       " 'deep',\n",
       " 'defect',\n",
       " 'degree',\n",
       " 'delegate',\n",
       " 'deliver',\n",
       " 'deploy',\n",
       " 'deployed',\n",
       " 'deployment',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'detail',\n",
       " 'detection',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'development',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'digital',\n",
       " 'director',\n",
       " 'disadvantaged',\n",
       " 'discovery',\n",
       " 'distribution',\n",
       " 'distributors',\n",
       " 'diverse',\n",
       " 'django',\n",
       " 'documentation',\n",
       " 'does',\n",
       " 'domain',\n",
       " 'douyin',\n",
       " 'downtime',\n",
       " 'dozen',\n",
       " 'driven',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'droved',\n",
       " 'dryers',\n",
       " 'duration',\n",
       " 'during',\n",
       " 'dyson',\n",
       " 'early',\n",
       " 'edge',\n",
       " 'educate',\n",
       " 'education',\n",
       " 'educational',\n",
       " 'efficiently',\n",
       " 'embed',\n",
       " 'employees',\n",
       " 'en',\n",
       " 'encourage',\n",
       " 'end',\n",
       " 'engage',\n",
       " 'engine',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'enjoy',\n",
       " 'enrich',\n",
       " 'entertain',\n",
       " 'entrepreneurship',\n",
       " 'environment',\n",
       " 'environments',\n",
       " 'etc',\n",
       " 'evaluation',\n",
       " 'exceptionally',\n",
       " 'exchange',\n",
       " 'excite',\n",
       " 'executed',\n",
       " 'execution',\n",
       " 'experience',\n",
       " 'experiences',\n",
       " 'expertise',\n",
       " 'extreme',\n",
       " 'facilitate',\n",
       " 'factories',\n",
       " 'factorization',\n",
       " 'familiar',\n",
       " 'fast',\n",
       " 'featured',\n",
       " 'features',\n",
       " 'feedback',\n",
       " 'feedbacks',\n",
       " 'fellows',\n",
       " 'field',\n",
       " 'financial',\n",
       " 'firefox',\n",
       " 'first',\n",
       " 'flask',\n",
       " 'flow',\n",
       " 'for',\n",
       " 'forecast',\n",
       " 'founded',\n",
       " 'founder',\n",
       " 'framework',\n",
       " 'francisco',\n",
       " 'from',\n",
       " 'front',\n",
       " 'functions',\n",
       " 'game',\n",
       " 'general',\n",
       " 'generated',\n",
       " 'geographies',\n",
       " 'get',\n",
       " 'global',\n",
       " 'globe',\n",
       " 'goal',\n",
       " 'golang',\n",
       " 'good',\n",
       " 'google',\n",
       " 'gpu',\n",
       " 'grads',\n",
       " 'graduate',\n",
       " 'great',\n",
       " 'growing',\n",
       " 'guaranteed',\n",
       " 'hadoop',\n",
       " 'hand',\n",
       " 'has',\n",
       " 'health',\n",
       " 'heart',\n",
       " 'helo',\n",
       " 'high',\n",
       " 'history',\n",
       " 'honor',\n",
       " 'honors',\n",
       " 'honour',\n",
       " 'hope',\n",
       " 'hopkins',\n",
       " 'host',\n",
       " 'https',\n",
       " 'hybrid',\n",
       " 'ideas',\n",
       " 'identified',\n",
       " 'identity',\n",
       " 'if',\n",
       " 'ijcai',\n",
       " 'image',\n",
       " 'implement',\n",
       " 'implementation',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'including',\n",
       " 'inclusive',\n",
       " 'inconsistency',\n",
       " 'increase',\n",
       " 'individuals',\n",
       " 'industrial',\n",
       " 'industries',\n",
       " 'inference',\n",
       " 'inform',\n",
       " 'infrastructure',\n",
       " 'initiate',\n",
       " 'innovative',\n",
       " 'insight',\n",
       " 'inspire',\n",
       " 'instead',\n",
       " 'institute',\n",
       " 'integer',\n",
       " 'integrating',\n",
       " 'intelligence',\n",
       " 'interest',\n",
       " 'intern',\n",
       " 'internal',\n",
       " 'international',\n",
       " 'internship',\n",
       " 'interview',\n",
       " 'into',\n",
       " 'iq',\n",
       " 'is',\n",
       " 'ivan',\n",
       " 'ivanthinks',\n",
       " 'ivanzhou',\n",
       " 'iyt',\n",
       " 'january',\n",
       " 'jetson',\n",
       " 'job',\n",
       " 'jobs',\n",
       " 'johns',\n",
       " 'july',\n",
       " 'june',\n",
       " 'knowledge',\n",
       " 'kubeflow',\n",
       " 'kubernetes',\n",
       " 'lab',\n",
       " 'labeling',\n",
       " 'labs',\n",
       " 'landing',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'large',\n",
       " 'largest',\n",
       " 'latency',\n",
       " 'lead',\n",
       " 'leads',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'least',\n",
       " 'led',\n",
       " 'lending',\n",
       " 'life',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'limited',\n",
       " 'linear',\n",
       " 'lines',\n",
       " 'linkedin',\n",
       " 'list',\n",
       " 'lite',\n",
       " 'local',\n",
       " 'locations',\n",
       " 'logistic',\n",
       " 'long',\n",
       " 'love',\n",
       " 'lrec',\n",
       " 'machine',\n",
       " 'machines',\n",
       " 'maintain',\n",
       " 'maintenance',\n",
       " 'making',\n",
       " 'management',\n",
       " 'manufacturing',\n",
       " 'many',\n",
       " 'march',\n",
       " 'margin',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'marketplace',\n",
       " 'markets',\n",
       " 'master',\n",
       " 'matrix',\n",
       " 'may',\n",
       " 'medium',\n",
       " 'meetings',\n",
       " 'members',\n",
       " 'mesos',\n",
       " 'metrics',\n",
       " 'microsoft',\n",
       " 'million',\n",
       " 'milliseconds',\n",
       " 'minimum',\n",
       " 'mining',\n",
       " 'mission',\n",
       " 'mixed',\n",
       " 'ml',\n",
       " 'model',\n",
       " 'models',\n",
       " 'modern',\n",
       " 'monitoring',\n",
       " 'month',\n",
       " 'months',\n",
       " 'more',\n",
       " 'most',\n",
       " 'motivation',\n",
       " 'mountain',\n",
       " 'mozilla',\n",
       " 'multi',\n",
       " 'multiple',\n",
       " 'mun',\n",
       " 'mxnet',\n",
       " 'my',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'natural',\n",
       " 'nd',\n",
       " 'need',\n",
       " 'negotiation',\n",
       " 'net',\n",
       " 'network',\n",
       " 'networking',\n",
       " 'neural',\n",
       " 'new',\n",
       " 'nlp',\n",
       " 'nn',\n",
       " 'nodejs',\n",
       " 'non',\n",
       " 'nonlinear',\n",
       " 'normal',\n",
       " 'not',\n",
       " 'novel',\n",
       " 'november',\n",
       " 'now',\n",
       " 'nserc',\n",
       " 'nvidia',\n",
       " 'october',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'operate',\n",
       " 'operating',\n",
       " 'operation',\n",
       " 'operations',\n",
       " 'optimization',\n",
       " 'optimize',\n",
       " 'optimized',\n",
       " 'or',\n",
       " 'orchestration',\n",
       " 'orchestrations',\n",
       " 'org',\n",
       " 'organize',\n",
       " 'organized',\n",
       " 'ota',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outperformed',\n",
       " 'outreached',\n",
       " 'over',\n",
       " 'oversee',\n",
       " 'own',\n",
       " 'page',\n",
       " 'paper',\n",
       " 'participate',\n",
       " 'passionate',\n",
       " 'people',\n",
       " 'performance',\n",
       " 'personal',\n",
       " 'personalization',\n",
       " 'personalized',\n",
       " 'perspectives',\n",
       " 'petuum',\n",
       " 'phd',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'photographer',\n",
       " 'photos',\n",
       " 'pipeline',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planning',\n",
       " 'platform',\n",
       " 'platforms',\n",
       " 'please',\n",
       " 'portfolio',\n",
       " 'position',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'pp',\n",
       " 'practice',\n",
       " 'precision',\n",
       " 'prediction',\n",
       " 'preference',\n",
       " 'present',\n",
       " 'president',\n",
       " 'pressure',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'product',\n",
       " 'production',\n",
       " 'products',\n",
       " 'professional',\n",
       " 'professionals',\n",
       " 'professor',\n",
       " 'professors',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'promote',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'providing',\n",
       " 'provincial',\n",
       " 'provisioning',\n",
       " 'public',\n",
       " 'publication',\n",
       " 'publications',\n",
       " 'published',\n",
       " 'purchase',\n",
       " 'pursuing',\n",
       " 'px',\n",
       " 'python',\n",
       " 'pytorch',\n",
       " 'qualifications',\n",
       " 'quality',\n",
       " 'quantify',\n",
       " 'range',\n",
       " 'rate',\n",
       " 'rbc',\n",
       " 'rdma',\n",
       " 'reach',\n",
       " 'react',\n",
       " 'real',\n",
       " 'reasonable',\n",
       " 'recall',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'recommend',\n",
       " 'recommendation',\n",
       " 'recommender',\n",
       " 'recording',\n",
       " 'recruit',\n",
       " 'recruitment',\n",
       " 'recsys',\n",
       " 'redesign',\n",
       " 'reduce',\n",
       " 'reflects',\n",
       " 'rehabilitation',\n",
       " 'related',\n",
       " 'reliability',\n",
       " 'research',\n",
       " 'researched',\n",
       " 'resources',\n",
       " 'responsibilities',\n",
       " 'resso',\n",
       " 'results',\n",
       " 'revenue',\n",
       " 'reviewed',\n",
       " 'rolling',\n",
       " 'rotman',\n",
       " 'run',\n",
       " 'sail',\n",
       " 'sales',\n",
       " 'salesforce',\n",
       " 'san',\n",
       " 'sanner',\n",
       " 'sap',\n",
       " 'sas',\n",
       " 'scale',\n",
       " 'scaling',\n",
       " 'schedule',\n",
       " 'school',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'search',\n",
       " 'secondary',\n",
       " 'segmentation',\n",
       " 'self',\n",
       " 'seminars',\n",
       " 'sentiment',\n",
       " 'september',\n",
       " 'server',\n",
       " 'services',\n",
       " 'set',\n",
       " 'setting',\n",
       " 'shanghai',\n",
       " 'share',\n",
       " 'shopify',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'sign',\n",
       " 'significant',\n",
       " 'skills',\n",
       " 'small',\n",
       " 'so',\n",
       " 'social',\n",
       " 'software',\n",
       " 'sold',\n",
       " 'solution',\n",
       " 'solutions',\n",
       " 'solve',\n",
       " 'solving',\n",
       " 'space',\n",
       " 'spark',\n",
       " 'specialist',\n",
       " 'specialization',\n",
       " 'sql',\n",
       " 'squadron',\n",
       " 'standard',\n",
       " 'stanford',\n",
       " 'start',\n",
       " 'started',\n",
       " 'starts',\n",
       " 'startups',\n",
       " 'state',\n",
       " 'storage',\n",
       " 'strategies',\n",
       " 'strengths',\n",
       " 'strong',\n",
       " 'structuring',\n",
       " 'student',\n",
       " 'students',\n",
       " 'successfully',\n",
       " 'such',\n",
       " 'suite',\n",
       " 'summary',\n",
       " 'summer',\n",
       " 'supervised',\n",
       " 'support',\n",
       " 'svm',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'targeted',\n",
       " 'team',\n",
       " 'teams',\n",
       " 'techniques',\n",
       " 'technologies',\n",
       " 'technology',\n",
       " 'temporal',\n",
       " 'tenant',\n",
       " 'tensorflow',\n",
       " 'term',\n",
       " 'test',\n",
       " 'th',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'thesis',\n",
       " 'they',\n",
       " 'this',\n",
       " 'thousands',\n",
       " 'three',\n",
       " 'through',\n",
       " 'tickets',\n",
       " 'tiktok',\n",
       " 'time',\n",
       " 'to',\n",
       " 'too',\n",
       " 'tool',\n",
       " 'top',\n",
       " 'toronto',\n",
       " 'toutiao',\n",
       " 'trained',\n",
       " 'training',\n",
       " 'transition',\n",
       " 'translation',\n",
       " 'trinity',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'uber',\n",
       " 'udacity',\n",
       " 'ui',\n",
       " 'uk',\n",
       " 'under',\n",
       " 'undergraduate',\n",
       " 'unique',\n",
       " 'united',\n",
       " 'university',\n",
       " 'unsupervised',\n",
       " 'up',\n",
       " 'ups',\n",
       " 'us',\n",
       " 'usability',\n",
       " 'used',\n",
       " 'user',\n",
       " 'users',\n",
       " 'using',\n",
       " 'usrc',\n",
       " 'ux',\n",
       " 'valued',\n",
       " 'variety',\n",
       " 'ventures',\n",
       " 'vertical',\n",
       " 'view',\n",
       " 'vision',\n",
       " 'visual',\n",
       " 'visualization',\n",
       " 'voices',\n",
       " 'volumes',\n",
       " 'vp',\n",
       " 'ways',\n",
       " 'we',\n",
       " 'web',\n",
       " 'weeks',\n",
       " 'westcan',\n",
       " 'wharton',\n",
       " 'where',\n",
       " 'will',\n",
       " 'win',\n",
       " 'with',\n",
       " 'within',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'workplace',\n",
       " 'worldwide',\n",
       " 'would',\n",
       " 'www',\n",
       " 'yacht',\n",
       " 'yarn',\n",
       " 'year',\n",
       " 'years',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your',\n",
       " 'zhou']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "# tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "# tfidf_transformer.fit(count_matrix)\n",
    "# # print idf values\n",
    "# df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# # sort ascending \n",
    "# df_idf.sort_values(by=['idf_weights'])\n",
    "\n",
    "# # count matrix \n",
    "# count_vector=cv.transform(resume) \n",
    " \n",
    "# # tf-idf scores \n",
    "# tf_idf_vector=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_candidate = resume_parser.extract_skills(resume)\n",
    "skills_jd = resume_parser.extract_skills(job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Metrics',\n",
       " 'Crm',\n",
       " 'Training',\n",
       " 'Recruit',\n",
       " 'Ai',\n",
       " 'International',\n",
       " 'Matrix',\n",
       " 'Consulting',\n",
       " 'Marketing',\n",
       " 'Accounting',\n",
       " 'Mining',\n",
       " 'Business intelligence',\n",
       " 'Cloud',\n",
       " 'Analytics',\n",
       " 'Hadoop',\n",
       " 'Segmentation',\n",
       " 'Ui',\n",
       " 'Ux',\n",
       " 'Health',\n",
       " 'Negotiation',\n",
       " 'Design',\n",
       " 'Plan',\n",
       " 'Visual',\n",
       " 'Communication',\n",
       " 'Engineering',\n",
       " 'System',\n",
       " 'Salesforce',\n",
       " 'Sql',\n",
       " 'Cola',\n",
       " 'Front-end',\n",
       " 'Analysis',\n",
       " 'Business process',\n",
       " 'Schedule',\n",
       " 'Sas',\n",
       " 'Networking',\n",
       " 'Computer science',\n",
       " 'Tensorflow',\n",
       " 'Research',\n",
       " 'Programming',\n",
       " 'Usability',\n",
       " 'Spark',\n",
       " 'Distribution',\n",
       " 'Algorithms',\n",
       " 'Process',\n",
       " 'Operations',\n",
       " 'Sales',\n",
       " 'Data collection',\n",
       " 'Sap',\n",
       " 'Database']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analytical',\n",
       " 'C',\n",
       " 'Recruitment',\n",
       " 'Training',\n",
       " 'Mxnet',\n",
       " 'Django',\n",
       " 'Documentation',\n",
       " 'Python',\n",
       " 'Communication',\n",
       " 'Engineering',\n",
       " 'System',\n",
       " 'Content',\n",
       " 'Flask',\n",
       " 'Pytorch',\n",
       " 'Computer science',\n",
       " 'Tensorflow',\n",
       " 'C++',\n",
       " 'Architecture',\n",
       " 'Programming',\n",
       " 'Process']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_jd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 : Raw Skill Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores without lemma and stop words:\n",
      "[[1.         0.30123762]\n",
      " [0.30123762 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "skills = [' '.join(skills_jd),' '.join(skills_candidate)]\n",
    "cv = CountVectorizer()\n",
    "skills_matrix = cv.fit_transform(skills)\n",
    "#Print the similarity scores\n",
    "print(\"\\nSimilarity Scores without lemma and stop words:\")\n",
    "print(cosine_similarity(skills_matrix))\n",
    "threshold = 0.2\n",
    "\n",
    "# this one is lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 : Matching by training vectorizer first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The cosine similarity for the resume is 0.662.\n"
     ]
    }
   ],
   "source": [
    "def vect_cos(vect, resume_list):\n",
    "    \"\"\" Vectorise text and compute the cosine similarity \"\"\"\n",
    "    query_0 = vect.transform([' '.join(vect.get_feature_names())])\n",
    "    query_1 = vect.transform(resume_list)\n",
    "    cos_sim = cosine_similarity(query_0.A, query_1.A)  # displays the resulting matrix\n",
    "    return query_1, np.round(cos_sim.squeeze(), 3)\n",
    "\n",
    "vectoriser = CountVectorizer().fit(skills_jd)\n",
    "\n",
    "# Analyze candidate\n",
    "resume_vect, resume_cos = vect_cos(vectoriser, [' '.join(skills_candidate)])\n",
    "print('\\nThe cosine similarity for the resume is {}.'.format(resume_cos))\n",
    "\n",
    "# this seems to give higher scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity for the resume is 0.25555062599997597.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# count word occurrences\n",
    "resume_vals = Counter(skills_candidate)\n",
    "jd_vals = Counter(skills_jd)\n",
    "\n",
    "# convert to word-vectors\n",
    "words  = list(resume_vals.keys() | jd_vals.keys())\n",
    "resume_vect = [resume_vals.get(word, 0) for word in words]\n",
    "jd_vect = [jd_vals.get(word, 0) for word in words]        # [1, 1, 1, 0, 1, 0]\n",
    "\n",
    "# find cosine\n",
    "len_r  = sum(rv*rv for rv in resume_vect) ** 0.5             # sqrt(7)\n",
    "len_jd  = sum(jdv*jdv for jdv in jd_vect) ** 0.5             # sqrt(4)\n",
    "dot    = sum(rv*jdv for rv,jdv in zip(resume_vect, jd_vect))    # 3\n",
    "cosine = dot / (len_a * len_b)\n",
    "print('The cosine similarity for the resume is {}.'.format(cosine))\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
